---
title             : "Theoretical Bias, as a function of population parameters"
shorttitle        : "Theoretical Bias"

author: 
  - name          : "Delacre Marie"
    affiliation   : "1"
    corresponding : no    # Define only one corresponding author
    address       : ""
    email         : ""

affiliation:
  - id            : "1"
    institution   : "ULB"

keywords          : "keywords"
wordcount         : "X"

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

# The bias 

For all estimators, when the population effect size is null so is the bias. We will therefore focus on configurations where there is a non-null population effect size. The sampling distribution of Cohen's $d_s$ (and therefore its bias) is only known under the assumptions of normality and homoscedasticity. On the other side, the biases of Glass's $d_s$, Cohen's $d'_s$ and Shieh's $d_s$ are theoretically known for all configurations where the normality assumption is met, whatever variances are equal across groups or not. In order to simplify the analysis of their bias, it is convenient to subdivise all configurations into 3 conditions:  
- when variances are equal across populations;     
- when variances are unequal across populations, with equal sample sizes;  
- when variances are unequal across populations, with unequal sample sizes.  

## Preliminary note

For all previously mentioned estimators (Cohen's $d_s$, Glass's $d_s$, Cohen's $d'_s$ and Shieh's $d_s$), the theoretical expectancy is computed by multiplying the population effect size by the following multiplier coefficient:

\begin{equation} 
\gamma=\frac{\sqrt{\frac{df}{2}} \times \Gamma{\frac{df-1}{2}}}{\Gamma{\frac{df}{2}}}
(\#eq:mc)
\end{equation} 

Where $df$ are the degrees of freedom. $\gamma$ is *always* positive, meaning that when the population effect size is not zero, all estimators will overestimate the real population effect size. Moreover, its limit tends to 1 when the degrees of freedom ($df$) tend to infinity, meaning that the larger the degrees of freedom, the lower the bias. 

## Cohen's $d_s$ (see Table 1)

Under the assumptions that independant residuals are normally distributed with equal variances, the **bias** of Cohen's $d_s$ is a function of total sample size (N) and the population effect size ($\delta_{Cohen}$):     

  + The larger the population effect size, the more Cohen's $d_s$ will overestimate $\delta_{Cohen}$.   
  
```{r biascohendNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:150){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = n1+n2-2
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biascohendNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d_s$, when variances are equal across groups, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF,xlab="N")
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biascohendNsize2}).

  + Of course, considering the degrees of freedom, the sample size ratio does not matter (i.e. the bias will decrease, whatever one increases $n_1$, $n_2$ or both sample sizes)

## Glass's $d_s$ (see Table 2)

Because degrees of freedom depend only on the sample size of the control group, there is no need to distinguish between cases where there is homoscedasticity or heteroscedasticity!   

The **bias** of Glass's $d_s$ is a function of the sample size of the control group ($n_c$) and the population effect size ($\delta_{glass}$):  

  + The larger the population effect size, the more Glass's $d_s$ will overestimate $\delta_{Glass}$.

```{r biasGlassctrlsize,include=FALSE}
Nctrl=NULL
coeffmult1=NULL
DF1=NULL

for (i in 4:200){
  nc=i
  ne=20
  Nctrl=c(Nctrl,nc)
  df = nc-2
  DF1 = c(DF1,df)
  coeffmult1 = c(coeffmult1,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}

Nexp=NULL
coeffmult2=NULL
DF2=NULL

for (i in 4:200){
  nc=20
  ne=i
  Nexp=c(Nexp,ne)
  df = nc-2
  DF2 = c(DF2,df)
  coeffmult2 = c(coeffmult2,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}

```

```{r biasGlassctrlsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Glass's $d_s$, as a function of $n_c$ (top) and $n_e$ (bottom)",echo=FALSE}
par(mfrow=c(2,2))
plot(Nctrl,DF1,xlab=expression(n[c]),ylab="DF")
plot(Nctrl,coeffmult1,xlab=expression(n[c]),ylab=expression(gamma))

plot(Nexp,DF2,xlab=expression(n[e]),ylab="DF")
plot(Nexp,coeffmult2,xlab=expression(n[e]),ylab=expression(gamma))
```

  + The larger the size of the control group, the lower the bias (see the two top plots in Figure \ref{fig:biasGlassctrlsize2}). On the other side, increasing the size of the experimental group does not impact the bias (see the two bottom plots in Figure \ref{fig:biasGlassctrlsize2}).

## Cohen's $d'_s$ (see Table 3)

### When variances are equal across populations

When $\sigma_1=\sigma_2=\sigma$: 
$$df_{Cohen's \; d'_s} = \frac{(n_1-1)(n_2-1)(2\sigma^2)^2}{(n_2-1)\sigma^4+(n_1-1)\sigma^4} = \frac{(n_1-1)(n_2-1)\times 4\sigma^4}{\sigma^4(n_1+n_2-2)} = \frac{4(n_1-1)(n_2-1)}{n_1+n_2-2}$$ 
One can see that degrees of freedom depend only on the total sample size (N) and the sample size allocation ratio ($\frac{n_1}{n_2}$). As a consequence, the **bias** of Cohen's $d'_s$ is a function of the population effect size ($\delta'_{Cohen}$), the sample size allocation ratio and the total sample size ($N$). 

  + The larger the population effect size, the more $Cohen's \; d'_s$ will overestimate $\delta'_{Cohen}$

```{r biascohendprimehomNratio,include=FALSE}
coeffmult <- NULL
nratio <- NULL
DF <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 2
  sd2 <- 2
  
  nratio <- c(nratio,n1/n2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
  
}
```

```{r biascohendprimehomNratio2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances are equal across groups, as a function of the logarithm of the sample sizes ratio $log\\left(\\frac{n_1}{n_2} \\right)$",echo=FALSE}
par(mfrow=c(1,2))
plot(log(nratio),DF,xlab=expression(paste("log(",sigma[1],"/",sigma[2],")")))
abline(v=0)
#nratio[DF==max(DF)]
plot(log(nratio),coeffmult,ylim=c(1,1.02),ylab=expression(gamma),xlab=expression(paste("log(",sigma[1],"/",sigma[2],")")))
abline(v=0)
#nratio[coeffmult==min(coeffmult)]
```

  + The further the sample size allocation ratio is from 1, the larger the bias (see Figure \ref{fig:biascohendprimehomNratio2})

```{r biascohendprimehomNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4) 
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biascohendprimehomNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances are equal across groups, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF,xlab="N")
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biascohendprimehomNsize2})

### When variances are unequal across populations, with equal sample sizes

When $n_1=n_2=n$: 
$$df_{Cohen's \; d'_s} = \frac{(n-1)^2(\sigma^2_1+\sigma^2_2)^2}{(n-1)(\sigma^4_1+\sigma^4_2)} =  \frac{(n-1)(\sigma^4_1+\sigma^4_2+2\sigma^2_1\sigma^2_2)}{\sigma^4_1+\sigma^4_2}$$ 
One can see that degrees of freedom depend only on the total sample size  (N) and the SD-ratio. As a consequence, the **bias** of Cohen's $d'_s$ is a function of the population effect size ($\delta'_{Cohen}$), the SD-ratio and the total sample size ($N$): 

  + The larger the population effect size, the more $Cohen's \; d'_s$ will overestimate $\delta'_{Cohen}$  

```{r biascohendprimehetbalSDratio,include=FALSE}
coeffmult <- NULL
SDratio <- NULL
DF <- NULL

for (i in 1:100){
  
  n1=100
  n2=100
  N <- n1+n2
  sd2 <- 10
  sd1 <- i
  
  SDratio <- c(SDratio,sd1/sd2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biascohendprimehetbalSDratio2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances are unequal across groups and sample sizes are equal, as a function of the logarithm of the $SD$-ratio ($log \\left( \\frac{\\sigma_1}{\\sigma_2} \\right)$)",echo=FALSE}
par(mfrow=c(1,2))
plot(log(SDratio),DF,,xlab=expression(paste("log(",sigma[1],"/",sigma[2],")")))
#SDratio[DF==max(DF)]
plot(log(SDratio),coeffmult,ylab=expression(gamma),xlab=expression(paste("log(",sigma[1],"/",sigma[2],")")))
#SDratio[coeffmult==min(coeffmult)]
```

  + The further the $SD$-ratio is from 1, the larger the bias (see Figure \ref{fig:biascohendprimehetbalSDratio2})  

```{r biascohendprimehetbalNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=10
sd2=2

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4) 
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biascohendprimehetbalNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances are unequal across groups and sample sizes are equal, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF,xlab="N")
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biascohendprimehetbalNsize2})  

```{r biascohendprimehetbalvariance,include=FALSE}
coeffmult <- NULL
SD1 <- NULL
SD2 <- NULL
DF <- NULL

for (i in 1:100){
  n1=100
  n2=100
  N <- n1+n2
  sdratio = 1/2
  sd1 <- i
  sd2 <- sdratio*i

  SD1 <- c(SD1,sd1)
  SD2 <- c(SD2,sd2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biascohendprimehetbalvariance2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances are unequal across groups and sample sizes are equal, as a function of $\\sigma_1$ and $\\sigma_2$, for a constant $SD$-ratio",echo=FALSE}
par(mfrow=c(2,2))
plot(SD1,DF,xlab=expression(sigma[1]))
#SDratio[DF==max(DF)]
plot(SD1,coeffmult,ylab=expression(gamma),xlab=expression(sigma[1]))
#SDratio[coeffmult==min(coeffmult)]

plot(SD2,DF,xlab=expression(sigma[1]))
#SDratio[DF==max(DF)]
plot(SD2,coeffmult,ylab=expression(gamma),xlab=expression(sigma[1]))
#SDratio[coeffmult==min(coeffmult)]

```

Note: for a constant $SD$-ratio, $\sigma_1$ and $\sigma_2$ don't matter (see Figure \ref{fig:biascohendprimehetbalvariance2}) 

### When variances are unequal across populations, with unequal sample sizes

The **bias** of Cohen's $d'_s$ is a function of the population effect size ($\delta'_{Cohen}$), the total sample size, and the interaction between the sample sizes ratio ($\frac{n_1}{n_2}$) and the $SD$-ratio ($\frac{\sigma_1}{\sigma_2}$):     

  + The larger the population effect size, the more $Cohen's \; d'_s$ will overestimate $\delta'_{Cohen}$  

```{r biascohendprimehetunbalNsize,include=FALSE}
coeffmult <- NULL
Nsize <- NULL
DF <- NULL

for (i in 2:80){
  
  n1 <- 3*i
  n2 <- i
  N <- n1+n2
  sd1 <- 1.8
  sd2 <- 1
  
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  Nsize <- c(Nsize,N)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biascohendprimehetunbalNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances and sample sizes are unequal across groups, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF,xlab="N")
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
```

  + The larger the total sample size, the lower the bias (see in Figure \ref{fig:biascohendprimehetunbalNsize2})

```{r biascohendprimehetunbalNratio,include=FALSE}
coeffmult2 <- NULL
nratio2 <- NULL
DF2 <- NULL
DF_NUM2 <- NULL
DF_DENOM2 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd2 <- 1
  sd1 <- sqrt(50-sd2^2) # so sqrt((sd1^2+sd2^2)/2)=5
  SDratio2=sd1/sd2
  nratio2 <- c(nratio2,n1/n2)
  df_num <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)
  df_denom <- ((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF_NUM2 <- c(DF_NUM2, df_num)
  DF_DENOM2 <- c(DF_DENOM2, df_denom)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF2 <- c(DF2,df)
  coeffmult2 <- c(coeffmult2,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

coeffmult3 <- NULL
nratio3 <- NULL
DF3 <- NULL
DF_NUM3 <- NULL
DF_DENOM3 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd2 <- 2
  sd1 <- sqrt(50-sd2^2) # so sqrt((sd1^2+sd2^2)/2)=5
  SDratio3=sd1/sd2
  nratio3 <- c(nratio3,n1/n2)
  df_num <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)
  df_denom <- ((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF_NUM3 <- c(DF_NUM3, df_num)
  DF_DENOM3 <- c(DF_DENOM3, df_denom)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF3 <- c(DF3,df)
  coeffmult3 <- c(coeffmult3,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

coeffmult4 <- NULL
nratio4 <- NULL
DF4 <- NULL
DF_NUM4 <- NULL
DF_DENOM4 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd2 <- 4
  sd1 <- sqrt(50-sd2^2) # so sqrt((sd1^2+sd2^2)/2)=5
  SDratio4=sd1/sd2
  nratio4 <- c(nratio4,n1/n2)
  df_num <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)
  df_denom <- ((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF_NUM4 <- c(DF_NUM4, df_num)
  DF_DENOM4 <- c(DF_DENOM4, df_denom)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF4 <- c(DF4,df)
  coeffmult4 <- c(coeffmult4,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biascohendprimehetunbaldfandbias,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances and sample sizes are unequal across groups, as a function of the logarithm of the sample sizes ratio ($log \\left( \\frac{n_1}{n_2} \\right)$), when $SD$-ratio equals 1.46 (first row), 3.39 (second row) or 7 (third row)",echo=FALSE}
par(mfrow=c(3,2))

plot(log(nratio4),DF4,ylab="DF",xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
plot(log(nratio4),coeffmult4,ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

plot(log(nratio3),DF3,ylab="DF",xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
plot(log(nratio3),coeffmult3,ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

plot(log(nratio2),DF2,ylab="DF",xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
plot(log(nratio2),coeffmult2,ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
```

  + The smallest bias always occure when there is a positive pairing between variances and sample size, because one gives more weight to the smallest variance in the denominator of the df computation. Moreover, the further the $SD$-ratio is from 1, the further from 1 will also be the sample sizes ratio associated with the smallest bias. This can be explained by splitting the numerator and the denominator in the DF computation (see Figure \ref{fig:biascohendprimehetunbaldfandbias}).
  
```{r biascohendprimehetunbalnumanddenomdf,fig.cap="numerator and denominator of the degrees of freedom (DF) computation, when computing the bias of Cohen's $d'_s$, when variances and sample sizes are unequal across groups, as a function of the logarithm of the sample sizes ratio ($log \\left( \\frac{n_1}{n_2} \\right)$), when $SD$-ratio equals 1.46 (first row), 3.39 (second row) or 7 (third row)",echo=FALSE}
par(mfrow=c(3,2))

plot(log(nratio4),DF_NUM4,ylab=expression(num[DF]),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
#nratio[DF_NUM3==max(DF_NUM3)]
plot(log(nratio4),DF_DENOM4,ylab=expression(denom[DF]),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

plot(log(nratio3),DF_NUM3,ylab=expression(num[DF]),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
#nratio[DF_NUM3==max(DF_NUM3)]
plot(log(nratio3),DF_DENOM3,ylab=expression(denom[DF]),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

plot(log(nratio2),DF_NUM2,ylab=expression(num[DF]),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
#nratio[DF_NUM2==max(DF_NUM2)]
plot(log(nratio2),DF_DENOM2,ylab=expression(denom[DF]),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
```

  As illustrated in Figure \ref{fig:biascohendprimehetunbalnumanddenomdf}, for any $SD$-ratio, the numerator of the degrees of freedom will be maximized when sample sizes are equal across groups (and is not impacted by the $SD$-ratio). On the other side, the denominator will be minimized when there is a positive pairing between variances and sample sizes. For example, when $\sigma_1>\sigma_2$, the smallest denominator occurs when $\frac{n_1}{n_2}=max(\frac{n_1}{n_2})$) and the larger the $SD$-ratio, the larger the impact of the sample sizes ratio on the denominator. In the end, the larger the $SD$-ratio, the further from 1 is the sample sizes ratio associated with the larger degrees of freedom.

```{r biascohendprimehetunbalvariance,include=FALSE}
coeffmult <- NULL
SD <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- 23
  n2 <- 75
  N <- n1+n2
  sd1 <- i
  sd2 <- 8*i
  
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  SD <- c(SD,sqrt((sd1^2+sd2^2)/2))
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biascohendprimehetunbalvariance2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Cohen's $d'_s$, when variances and sample sizes are unequal across groups, as a function of $\\sigma= \\frac{(\\sigma_1^2+\\sigma_2^2)}{2}$, for a constant $SD$-ratio",echo=FALSE}
par(mfrow=c(2,2))
plot(SD,DF,xlab=expression(sigma))
abline(v=0)
plot(SD,coeffmult,ylab=expression(gamma),xlab=expression(sigma))
abline(v=0)
```
  
Note: for a constant SD-ratio, the variance does not matter. (See Figure \ref{fig:biascohendprimehetunbalvariance2})


## Shieh's $d_s$ (see Table 4)

### When variances are equal across populations

When $\sigma_1=\sigma_2=\sigma$:
$$df_{Shieh's \; d_s} = \frac{\left( \frac{n_2\sigma^2+n_1\sigma^2}{n_1n_2}\right)^2}{\frac{(n_2-1)\left( \frac{\sigma^2}{n_1}\right)^2+(n_1-1)\left( \frac{\sigma^2}{n_2}\right)^2}{(n_1-1)(n_2-1)}}$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{[\sigma^2(n_1+n_2)]^2}{n_1^2n_2^2} \times \frac{(n_1-1)(n_2-1)}{(n_2-1) \times  \frac{\sigma^4}{n_1^2}+(n_1-1) \times \frac{\sigma^4}{n_2^2}}$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{\sigma^4N^2}{n_1^2n_2^2} \times \frac{(n_1-1)(n_2-1)}{\sigma^4 \left( \frac{n_2-1}{n^2_1}+\frac{n_1-1}{n^2_2}\right) }$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{N^2(n_1-1)(n_2-1)}{n_1^2n_2^2 \left( \frac{n_2^2(n_2-1)+n_1^2(n_1-1)}{n_1^2n_2^2}\right)}$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{N^2(n_1-1)(n_2-1)}{n_2^2(n_2-1)+n_1^2(n_1-1)}$$

One can see that degrees of freedom depend only on the total sample size ($N$) and the sample size allocation ratio ($\frac{n_1}{n_2}$). As a consequence, the **bias** of Shieh's $d'_s$ is a function of the population effect size ($\delta_{Shieh}$), the sample size allocation ratio ($\frac{n_1}{n_2}$) and the total sample size ($N$). 

  + The larger the population effect size, the more $Shieh's \; d_s$ will overestimate $\delta_{Shieh}$
  
```{r biasshiehhomNratio,include=FALSE}
coeffmult <- NULL
nratio <- NULL
DF <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 8
  sd2 <- 8
  
  nratio <- c(nratio,n1/n2)
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
  
}
```

```{r biasshiehhomNratio2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances are equal across groups, as a function of the logarithm of the sample sizes ratio $(log \\left(\\frac{n_1}{n_2})\\right)$",echo=FALSE}
par(mfrow=c(1,2))
plot(log(nratio),DF,xlab=expression(paste("log(",n[1],"/",n[2],")")))
#nratio[DF==max(DF)]
plot(log(nratio),coeffmult,ylim=c(1,1.02),ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
#nratio[coeffmult==min(coeffmult)]
```

  + The further the sample size allocation ratio is from 1, the larger the bias (see Figure \ref{fig:biasshiehhomNratio2})

```{r biasshiehhomNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:200){
  n1=2.45*i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biasshiehhomNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances are equal across groups, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF,xlab="N")
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biasshiehhomNsize2})


### When variances are unequal across populations, with equal sample sizes

When $n_1=n_2=n$:
$$df_{Shieh's \; d_s} = \frac{\left( \frac{\sigma_1^2+\sigma_2^2}{n} \right)^2}{\frac{(\sigma_1^2/n)^2+(\sigma_2^2/n)^2}{n-1}}$$
$$df_{Shieh's \; d_s} = \frac{(\sigma_1^2+\sigma_2^2)^2}{n^2} \times\frac{n-1}{\frac{\sigma_1^4+\sigma_2^4}{n^2}}$$
$$df_{Shieh's \; d_s} = \frac{(\sigma_1^2+\sigma_2^2)^2 \times (n-1)}{\sigma_1^4+\sigma_2^4}$$

One can see that degrees of freedom depend on the total sample size (N), the $SD$-ratio.  As a consequence, the bias depends on the population effect size ($\delta_{Shieh}$), the $SD$-ratio and the total sample size (N).

  + The larger the population effect size, the more $Shieh's \; d_s$ will overestimate $\delta_{Shieh}$  

```{r biasshiehhetbalSDratio,include=FALSE}
coeffmult <- NULL
SDratio <- NULL
DF <- NULL

for (i in 1:100){
  
  n1=100
  n2=100
  N <- n1+n2
  sd2 <- 10
  sd1 <- i
  
  SDratio <- c(SDratio,sd1/sd2)
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biasshiehhetbalSDratio2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances are unequal across groups and sample sizes are equal, as a function of the logarithm of the $SD$-ratio $(log \\left(\\frac{\\sigma_1}{\\sigma_2})\\right)$",echo=FALSE}
par(mfrow=c(1,2))
plot(log(SDratio),DF,xlab=expression(paste("log(",sigma[1],"/",sigma[2],")")))
#SDratio[DF==max(DF)]
plot(log(SDratio),coeffmult,ylab=expression(gamma),xlab=expression(paste("log(",sigma[1],"/",sigma[2],")")))
#SDratio[coeffmult==min(coeffmult)]
```

  + The further the SD-ratio is from 1, the larger the bias (see Figure \ref{fig:biasshiehhetbalSDratio2})  

```{r biasshiehhetbalNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=12
sd2=1.4786

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1)) 
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biasshiehhetbalNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances are unequal across groups and sample sizes are equal, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF,xlab="N")
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biasshiehhetbalNsize2})  

```{r biasshiehhetbalvariance,include=FALSE}
coeffmult <- NULL
SD1 <- NULL
DF <- NULL

for (i in 1:200){
  n1=100
  n2=100
  N <- n1+n2
  sdratio = 3
  sd1 <- i
  sd2 <- sdratio*i

  SD1 <- c(SD1,sd1)
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biasshiehhetbalvariance2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances are unequal across groups and sample sizes are equal, as a function of $\\sigma_1$, for a constant $SD$-ratio",echo=FALSE}
par(mfrow=c(1,2))
plot(SD1,DF,xlab=expression(sigma[1]))
#SDratio[DF==max(DF)]
plot(SD1,coeffmult,ylab=expression(gamma),xlab=expression(sigma[1]))
#SDratio[coeffmult==min(coeffmult)]
```

Note: for a constant SD-ratio, the size of the variance does not matter (see Figure \ref{fig:biasshiehhetbalvariance2}) 

### When variances are unequal across populations, with unequal sample sizes

The **bias** of Shieh's $d'_s$ is a function of the population effect size ($\delta_{Shieh}$), the sample sizes ($n_1$ and $n_2$), and the pairing between sample sizes, and variances and sample sizes ratios.

  + The larger the population effect size, the more $Shieh's \; d_s$ will overestimate $\delta_{Shieh}$  

```{r biasshiehhetunbalNsize,include=FALSE}
coeffmult <- NULL
Nsize <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- i
  n2 <- 12*i
  N <- n1+n2
  sd1 <- 1.8
  sd2 <- 1
  
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  Nsize <- c(Nsize,N)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biasshiehhetunbalNsize2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances and sample sizes are unequal across groups, as a function of the total sample size (N)",echo=FALSE}
par(mfrow=c(2,2))
plot(Nsize,DF,xlab="N")
abline(v=0)
plot(Nsize,coeffmult,ylab=expression(gamma),xlab="N")
abline(v=0)
```

  + The larger the sample sizes, the lower the bias (illustration in Figure \ref{fig:biasshiehhetunbalNsize2})

```{r biasshiehhetunbalNratio,include=FALSE}
coeffmult2 <- NULL
nratio2 <- NULL
DF2 <- NULL
DF_NUM2 <- NULL
DF_DENOM2 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 1
  sd2 <- sqrt(50-sd1^2) # so sqrt((sd1^2+sd2^2)/2)=5
  SDratio2=sd1/sd2
  nratio2 <- c(nratio2,n1/n2)
  df_num <- (sd1^2/n1+sd2^2/n2)^2
  df_denom <- ((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF2 <- c(DF2,df)
  DF_NUM2 <- c(DF_NUM2, df_num)
  DF_DENOM2 <- c(DF_DENOM2, df_denom)

  coeffmult2 <- c(coeffmult2,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

coeffmult3 <- NULL
nratio3 <- NULL
DF3 <- NULL
DF_NUM3 <- NULL
DF_DENOM3 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 2
  sd2 <- sqrt(50-sd1^2) # so sqrt((sd1^2+sd2^2)/2)=5
  SDratio3=sd1/sd2
  nratio3 <- c(nratio3,n1/n2)
  df_num <- (sd1^2/n1+sd2^2/n2)^2
  df_denom <- ((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF_NUM3 <- c(DF_NUM3, df_num)
  DF_DENOM3 <- c(DF_DENOM3, df_denom)
  DF3 <- c(DF3,df)
  
  coeffmult3 <- c(coeffmult3,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

coeffmult4 <- NULL
nratio4 <- NULL
DF4 <- NULL
DF_NUM4 <- NULL
DF_DENOM4 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 4
  sd2 <- sqrt(50-sd1^2) # so sqrt((sd1^2+sd2^2)/2)=5
  SDratio4=sd1/sd2
  nratio4 <- c(nratio4,n1/n2)
  df_num <- (sd1^2/n1+sd2^2/n2)^2
  df_denom <- ((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF_NUM4 <- c(DF_NUM4, df_num)
  DF_DENOM4 <- c(DF_DENOM4, df_denom)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF4 <- c(DF4,df)
  coeffmult4 <- c(coeffmult4,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biasshiehhetunbaldfandbias,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances and sample sizes are unequal across groups, as a function of the logarithm of the sample sizes ratio ($log \\left( \\frac{n_1}{n_2} \\right)$), when $SD$-ratio equals 1.46 (first row), 3.39 (second row) or 7 (third row)",echo=FALSE}
par(mfrow=c(3,2))

plot(log(nratio4),DF4,ylab="DF",xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
plot(log(nratio4),coeffmult4,ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

plot(log(nratio3),DF3,ylab="DF",xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
plot(log(nratio3),coeffmult3,ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

plot(log(nratio2),DF2,ylab="DF",xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)
plot(log(nratio2),coeffmult2,ylab=expression(gamma),xlab=expression(paste("log(",n[1],"/",n[2],")")))
abline(v=0)

```

  + The smallest bias always occure when there is a positive pairing between variances and sample size. Moreover, the further the $SD$-ratio is from 1, the further from 1 will also be the sample sizes ratio associated with the smallest bias. 

```{r biasshiehhetunbalvariance,include=FALSE}
coeffmult <- NULL
SD <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- 60
  n2 <- 12
  N <- n1+n2
  sd1 <- i
  sd2 <- 8*i
  
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  SD <- c(SD,sqrt((sd1^2+sd2^2)/2))
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biasshiehhetunbalvariance2,fig.cap="Degrees of freedom (DF) and $\\gamma$, when computing the bias of Shieh's $d_s$, when variances and sample sizes are unequal across groups, as a function of $\\sigma_1$ and $\\sigma_2$, for a constant $SD$-ratio",echo=FALSE}
par(mfrow=c(2,2))
plot(SD,DF,xlab=expression(sigma))
abline(v=0)
plot(SD,coeffmult,ylab=expression(gamma),xlab=expression(sigma))
abline(v=0)
```
  
Moreover, for a constant SD-ratio, the variances don't matter either. (See Figure \ref{fig:biasshiehhetunbalvariance2})