---
title             : "Theoretical Bias and variance, as a function of population parameters"
shorttitle        : "Theoretical Bias and variance"

author: 
  - name          : "Delacre Marie"
    affiliation   : "1"
    corresponding : no    # Define only one corresponding author
    address       : ""
    email         : ""

affiliation:
  - id            : "1"
    institution   : "ULB"

keywords          : "keywords"
wordcount         : "X"

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

# The bias 

For all estimators, when the population effect size is null so is the bias. We will subdivise all configurations when there is a non-null population effect into 3 conditions:  
- when variances are equal across groups,   
- when variances are unequal across groups, with equal sample sizes  
- when variances are unequal across groups, with unequal sample sizes  

## Cohen's $d_s$

### When variances are equal across populations

The **bias** of Cohen's $d_s$ is a function of total sample size (N) and the population effect size ($\delta_{Cohen}$):     

  + The larger the population effect size, the more Cohen's $d_s$ will overestimate $\delta_{Cohen}$.   
  
```{r biascohendNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = n1+n2-2
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biascohendNsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF)
plot(Nsize,coeffmult)
```

  + The larger the total sample size, the lower the bias. The bias tends to zero when the total sample size tends to infinity (see Figure \ref{fig:biascohendNsize2})

```{r biascohendNratio,include=FALSE}
coeffmult <- NULL
nratio <- NULL
DF <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 12
  sd2 <- 12
  
  nratio <- c(nratio,n1/n2)
  df <- n1+n2-2
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biascohendNratio2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(log(nratio),DF)
#nratio[DF==max(DF)]
plot(log(nratio),coeffmult,ylim=c(1,1.02))
#nratio[correction==min(coeffmult)]
```

Of course, considering the degrees of freedom, the sample size ratio does not matter...(see Figure \ref{fig:biascohendNratio2})

## Glass's $d_s$

Because degrees of freedom depend only on the sample size of the control group, there is no need to distinguish between cases where there is homoscedasticity or heteroscedasticity!   

The **bias** of Glass's $d_s$ is a function of the sample size of the control group ($n_c$) and the population effect size ($\delta_{glass}$):  

  + The larger the population effect size, the more Glass's $d_s$ will overestimate $\delta_{Glass}$.

```{r biasGlassctrlsize,include=FALSE}
Nctrl=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:200){
  n1=i
  n2=i
  Nctrl=c(Nctrl,n1)
  df = n1-2
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biasGlassctrlsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF)
plot(Nsize,coeffmult)
```

  + The larger the size of the control group, the lower the bias. The bias tends to zero when the sample size of the control group tends to infinity (see Figure \ref{fig:biasGlassctrlsize2})

## Cohen's $d'_s$

### When variances are equal across populations

When $\sigma_1=\sigma_2=\sigma$: 
$$df_{Cohen's \; d'_s} = \frac{(n_1-1)(n_2-1)(2\sigma^2)^2}{(n_2-1)\sigma^4+(n_1-1)\sigma^4} = \frac{(n_1-1)(n_2-1)\times 4\sigma^4}{\sigma^4(n_1+n_2-2)} = \frac{4(n_1-1)(n_2-1)}{n_1+n_2-2}$$ 
One can see that degrees of freedom depend only on the total sample size (N) and the sample size allocation ratio. As a consequence, the **bias** of Cohen's $d'_s$ is a function of the population effect size ($\delta'_{Cohen}$), the sample size allocation ratio and the total sample size ($N$). 

  + The larger the population effect size, the more $Cohen's \; d'_s$ will overestimate $\delta'_{Cohen}$

```{r biascohendprimehomNratio,include=FALSE}
coeffmult <- NULL
nratio <- NULL
DF <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 12
  sd2 <- 12
  
  nratio <- c(nratio,n1/n2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
  
}
```

```{r biascohendprimehomNratio2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(log(nratio),DF)
#nratio[DF==max(DF)]
plot(log(nratio),coeffmult,ylim=c(1,1.02))
#nratio[coeffmult==min(coeffmult)]
```

  + The further the sample size allocation ratio is from 1, the larger the bias (see Figure \ref{fig:biascohendprimehomNratio2})

```{r biascohendprimehomNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4) 
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biascohendprimehomNsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF)
plot(Nsize,coeffmult)
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biascohendprimehomNsize2})

### When variances are unequal across populations, with equal sample sizes

When $n_1=n_2=n$: 
$$df_{Cohen's \; d'_s} = \frac{(n-1)^2(\sigma^2_1+\sigma^2_2)^2}{(n-1)(\sigma^4_1+\sigma^4_2)} =  \frac{(n-1)(\sigma^4_1+\sigma^4_2+2\sigma^2_1\sigma^2_2)}{\sigma^4_1+\sigma^4_2}$$ 
One can see that degrees of freedom depend only on the total sample size  (N) and the SD-ratio. As a consequence, the **bias** of Cohen's $d'_s$ is a function of the population effect size ($\delta'_{Cohen}$), the SD-ratio and the total sample size ($N$): 

  + The larger the population effect size, the more $Cohen's \; d'_s$ will overestimate $\delta'_{Cohen}$  

```{r biascohendprimehetbalSDratio,include=FALSE}
coeffmult <- NULL
SDratio <- NULL
DF <- NULL

for (i in 1:100){
  
  n1=100
  n2=100
  N <- n1+n2
  sd2 <- 10
  sd1 <- i
  
  SDratio <- c(SDratio,sd1/sd2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biascohendprimehetbalSDratio2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(log(SDratio),DF)
#SDratio[DF==max(DF)]
plot(log(SDratio),coeffmult)
#SDratio[coeffmult==min(coeffmult)]
```

  + The further the SD-ratio is from 1, the larger the bias (see Figure \ref{fig:biascohendprimehetbalSDratio2})  

```{r biascohendprimehetbalNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=10
sd2=2

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4) 
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biascohendprimehetbalNsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF)
plot(Nsize,coeffmult)
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biascohendprimehetbalNsize2})  

```{r biascohendprimehetbalvariance,include=FALSE}
coeffmult <- NULL
SD1 <- NULL
DF <- NULL

for (i in 1:100){
  n1=100
  n2=100
  N <- n1+n2
  sdratio = 1/2
  sd1 <- i
  sd2 <- sdratio*i

  SD1 <- c(SD1,sd1)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biascohendprimehetbalvariance2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(SD1,DF)
#SDratio[DF==max(DF)]
plot(SD1,coeffmult)
#SDratio[coeffmult==min(coeffmult)]
```

Note: for a constant SD-ratio, the size of the variance does not matter (see Figure \ref{fig:biascohendprimehetbalvariance2}) 

### When variances are unequal across populations, with unequal sample sizes

The **bias** of Cohen's $d'_s$ is a function of the population effect size ($\delta'_{Cohen}$), the total sample size, and the sample sizes and variances pairing :     

  + The larger the population effect size, the more $Cohen's \; d'_s$ will overestimate $\delta'_{Cohen}$  

```{r biascohendprimehetunbalNratio,include=FALSE}
coeffmult <- NULL
nratio <- NULL
DF <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 2
  sd2 <- 10
  
  nratio <- c(nratio,n1/n2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

coeffmult2 <- NULL
nratio2 <- NULL
DF2 <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 10
  sd2 <- 2
  
  nratio2 <- c(nratio2,n1/n2)
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF2 <- c(DF2,df)
  coeffmult2 <- c(coeffmult2,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biascohendprimehetunbalNratio2,fig.cap="...",echo=FALSE}
par(mfrow=c(2,2))
plot(log(nratio),DF)
abline(v=0)
plot(log(nratio),coeffmult)
abline(v=0)

plot(log(nratio2),DF2)
abline(v=0)
plot(log(nratio2),coeffmult2)
abline(v=0)

```

  + When there is a positive pairing between sample sizes and variances, one gives more weight to the smallest variance. As a consequence, the denominator in the df computation decreases, the degrees of freedom increase and therefore, the bias decreases (see the two plots on the top in Figure \ref{fig:biascohendprimehetunbalNratio2}).  On the other size, where there is a negative pairing between sample sizes and variances, one gives more weight to the largest variance. As a consequence, the denominator in the df computatin increases, the degrees of freedom decrease and therefore, the bias increase (see the two plots in the bottom of Figure \ref{fig:biascohendprimehetunbalNratio2}).   

```{r biascohendprimehetunbalNsize,include=FALSE}
coeffmult <- NULL
Nsize <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- i
  n2 <- 12*i
  N <- n1+n2
  sd1 <- 1.8
  sd2 <- 1
  
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  Nsize <- c(Nsize,N)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biascohendprimehetunbalNsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(2,2))
plot(Nsize,DF)
abline(v=0)
plot(Nsize,coeffmult)
abline(v=0)
```

  + The larger the total sample size, the lower the bias (illustration in Figure \ref{fig:biascohendprimehetunbalNsize2})

```{r biascohendprimehetunbalvariance,include=FALSE}
coeffmult <- NULL
SD <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- 23
  n2 <- 75
  N <- n1+n2
  sd1 <- i
  sd2 <- 8*i
  
  df <- ((n1-1)*(n2-1)*(sd1^2+sd2^2)^2)/((n2-1)*sd1^4+(n1-1)*sd2^4)
  DF <- c(DF,df)
  SD <- c(SD,sqrt((sd1^2+sd2^2)/2))
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biascohendprimehetunbalvariance2,fig.cap="...",echo=FALSE}
par(mfrow=c(2,2))
plot(SD,DF)
abline(v=0)
plot(SD,coeffmult)
abline(v=0)
```
  
Note: for a constant SD-ratio, the variance does not matter. (See Figure \ref{fig:biascohendprimehetunbalvariance2})

## Shieh's $d_s$

### When variances are equal across populations

When $\sigma_1=\sigma_2=\sigma$:
$$df_{Shieh's \; d_s} = \frac{\left( \frac{n_2\sigma^2+n_1\sigma^2}{n_1n_2}\right)^2}{\frac{(n_2-1)\left( \frac{\sigma^2}{n_1}\right)^2+(n_1-1)\left( \frac{\sigma^2}{n_2}\right)^2}{(n_1-1)(n_2-1)}}$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{[\sigma^2(n_1+n_2)]^2}{n_1^2n_2^2} \times \frac{(n_1-1)(n_2-1)}{(n_2-1) \times  \frac{\sigma^4}{n_1^2}+(n_1-1) \times \frac{\sigma^4}{n_2^2}}$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{\sigma^4N^2}{n_1^2n_2^2} \times \frac{(n_1-1)(n_2-1)}{\sigma^4 \left( \frac{n_2-1}{n^2_1}+\frac{n_1-1}{n^2_2}\right) }$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{N^2(n_1-1)(n_2-1)}{n_1^2n_2^2 \left( \frac{n_2^2(n_2-1)+n_1^2(n_1-1)}{n_1^2n_2^2}\right)}$$
$$\leftrightarrow df_{Shieh's \; d_s} = \frac{N^2(n_1-1)(n_2-1)}{n_2^2(n_2-1)+n_1^2(n_1-1)}$$

One can see that degrees of freedom depend only on the total sample size (N) and the sample size allocation ratio. As a consequence, the **bias** of Shieh's $d'_s$ is a function of the population effect size ($\delta_{Shieh}$), the sample size allocation ratio and the total sample size ($N$). 

  + The larger the population effect size, the more $Shieh's \; d_s$ will overestimate $\delta_{Shieh}$
  
```{r biasshiehhomNratio,include=FALSE}
coeffmult <- NULL
nratio <- NULL
DF <- NULL

for (i in 10:190){
  
  N <- 200
  n1 <- i
  n2 <- N-n1
  sd1 <- 8
  sd2 <- 8
  
  nratio <- c(nratio,n1/n2)
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
  
}
```

```{r biasshiehhomNratio2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(log(nratio),DF)
#nratio[DF==max(DF)]
plot(log(nratio),coeffmult,ylim=c(1,1.02))
#nratio[coeffmult==min(coeffmult)]
```

  + The further the sample size allocation ratio is from 1, the larger the bias (see Figure \ref{fig:biasshiehhomNratio2})

```{r biasshiehhomNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=2
sd2=2

for (i in 4:200){
  n1=2.45*i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biasshiehhomNsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF)
plot(Nsize,coeffmult)
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biasshiehhomNsize2})


### When variances are unequal across populations, with equal sample sizes

When $n_1=n_2=n$:
$$df_{Shieh's \; d_s} = \frac{\left( \frac{\sigma_1^2+\sigma_2^2}{n} \right)^2}{\frac{(\sigma_1^2/n)^2+(\sigma_2^2/n)^2}{n-1}}$$
$$df_{Shieh's \; d_s} = \frac{(\sigma_1^2+\sigma_2^2)^2}{n^2} \times\frac{n-1}{\frac{\sigma_1^4+\sigma_2^4}{n^2}}$$
$$df_{Shieh's \; d_s} = \frac{(\sigma_1^2+\sigma_2^2)^2 \times (n-1)}{\sigma_1^4+\sigma_2^4}$$

One can see that degrees of freedom depend on the total sample size (N), the $SD$-ratio.  As a consequence, the bias depends on the population effect size ($\delta_{Shieh}$), the $SD$-ratio and the total sample size (N).

  + The larger the population effect size, the more $Shieh's \; d_s$ will overestimate $\delta_{Shieh}$  

```{r biasshiehhetbalSDratio,include=FALSE}
coeffmult <- NULL
SDratio <- NULL
DF <- NULL

for (i in 1:100){
  
  n1=100
  n2=100
  N <- n1+n2
  sd2 <- 10
  sd1 <- i
  
  SDratio <- c(SDratio,sd1/sd2)
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biasshiehhetbalSDratio2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
plot(log(SDratio),DF)
#SDratio[DF==max(DF)]
plot(log(SDratio),coeffmult)
#SDratio[coeffmult==min(coeffmult)]
```

  + The further the SD-ratio is from 1, the larger the bias (see Figure \ref{fig:biasshiehhetbalSDratio2})  

```{r biasshiehhetbalNsize,include=FALSE}
Nsize=NULL
coeffmult=NULL
DF=NULL

sd1=12
sd2=1.4786

for (i in 4:200){
  n1=i
  n2=i
  N = n1+n2
  Nsize=c(Nsize,N)
  df = (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1)) 
  DF = c(DF,df)
  coeffmult = c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))
}
```

```{r biasshiehhetbalNsize2,fig.cap="bias of Cohen's $d'_s$ as a function of the total sample size, when variances are equal across groups",echo=FALSE}
par(mfrow=c(1,2))
plot(Nsize,DF)
plot(Nsize,coeffmult)
```

  + The larger the total sample size, the lower the bias (see Figure \ref{fig:biasshiehhetbalNsize2})  

```{r biasshiehhetbalvariance,include=FALSE}
coeffmult <- NULL
SD1 <- NULL
DF <- NULL

for (i in 1:200){
  n1=100
  n2=100
  N <- n1+n2
  sdratio = 3
  sd1 <- i
  sd2 <- sdratio*i

  SD1 <- c(SD1,sd1)
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```

```{r biasshiehhetbalvariance2,fig.cap=";;;",echo=FALSE}
par(mfrow=c(1,2))
plot(SD1,DF)
#SDratio[DF==max(DF)]
plot(SD1,coeffmult)
#SDratio[coeffmult==min(coeffmult)]
```

Note: for a constant SD-ratio, the size of the variance does not matter (see Figure \ref{fig:biasshiehhetbalvariance2}) 

### When variances are unequal across populations, with unequal sample sizes

The **bias** of Shieh's $d'_s$ is a function of the population effect size ($\delta_{Shieh}$), the sample sizes ($n_1$ and $n_2$), and the pairing between sample sizes and variances and sample sizes ratios.

  + The larger the population effect size, the more $Shieh's \; d_s$ will overestimate $\delta_{Shieh}$  

```{r biasshiehhetunbalNsize,include=FALSE}
coeffmult <- NULL
Nsize <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- i
  n2 <- 12*i
  N <- n1+n2
  sd1 <- 1.8
  sd2 <- 1
  
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  Nsize <- c(Nsize,N)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biasshiehhetunbalNsize2,fig.cap="...",echo=FALSE}
par(mfrow=c(2,2))
plot(Nsize,DF)
abline(v=0)
plot(Nsize,coeffmult)
abline(v=0)
```

  + The larger the sample sizes, the lower the bias (illustration in Figure \ref{fig:biasshiehhetunbalNsize2})

```{r biasshiehhetunbalSDRN,include=FALSE}
SDNr1 <- NULL
SDNr2 <- NULL
NUM <- NULL
DENOM <- NULL
DF <- NULL
coeffmult <- NULL

for (i in 1:100){
  
  n1 <- 50
  n2 <- 20
  N <- n1+n2

  sdrn1 <- i
  sdrn2 <- i
  num <- (sdrn1+sdrn2)^2
  denom <- (sdrn1^2/(n1-1)+sdrn2^2/(n2-1))
  df <- num/denom
  
  SDNr1 <- c(SDNr1,sdrn1)
  SDNr2 <- c(SDNr2,sdrn2)
  NUM <- c(NUM,num)
  DENOM <- c(DENOM,denom)
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```


```{r biasshiehhetunbalSDRN2,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
#plot(SDNr2,NUM)
#plot(SDNr2,DENOM)
plot(SDNr1,DF)
plot(SDNr2,DF)
```

```{r biasshiehhetunbalSDRNandnpairingcase1,include=FALSE}
DF <- NULL
coeffmult <- NULL
Nratio <- NULL

for (i in 6:100){

  sdrn1 <- 1
  sdrn2 <- 1
  
  N = 106
  n1 <- i
  n2 <- N-i
  nratio <- n1/n2
  
  df <- (sdrn1+sdrn2)^2/(sdrn1^2/(n1-1)+sdrn2^2/(n2-1))
 
  Nratio <- c(Nratio,nratio)  
  DF <- c(DF,df)
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}
```


```{r biasshiehhetunbalSDRNandnpairing2case1,fig.cap="...",echo=FALSE}
par(mfrow=c(1,2))
#the plot(SDNr2,NUM)
#plot(SDNr2,DENOM)
plot(log(Nratio),DF)
#Nratio[DF==max(DF)]
plot(log(Nratio),coeffmult)
#Nratio[coeffmult==min(coeffmult)]
```

```{r biasshiehhetunbalSDRNandnpairingcase2,include=FALSE}
Nratio1 <- NULL
DF1 <- NULL
coeffmult1 <- NULL

for (i in 6:100){

  sdrn1 <- 1
  sdrn2 <- 2
  
  N = 106
  n1 <- i
  n2 <- N-i
  nratio <- n1/n2
  
  df <- (sdrn1+sdrn2)^2/(sdrn1^2/(n1-1)+sdrn2^2/(n2-1))
 
  Nratio1 <- c(Nratio1,nratio)  
  DF1 <- c(DF1,df)
  coeffmult1 <- c(coeffmult1,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

#----------------------------------------------------------------------

Nratio2 <- NULL
DF2 <- NULL
coeffmult2 <- NULL

for (i in 6:100){

  sdrn1 <- 1
  sdrn2 <- 10
  
  N = 106
  n1 <- i
  n2 <- N-i
  nratio <- n1/n2
  
  df <- (sdrn1+sdrn2)^2/(sdrn1^2/(n1-1)+sdrn2^2/(n2-1))
 
  Nratio2 <- c(Nratio2,nratio)  
  DF2 <- c(DF2,df)
  coeffmult2 <- c(coeffmult2,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

#----------------------------------------------------------------------

Nratio3 <- NULL
DF3 <- NULL
coeffmult3 <- NULL

for (i in 6:100){

  sdrn1 <- 2
  sdrn2 <- 1
  
  N = 106
  n1 <- i
  n2 <- N-i
  nratio <- n1/n2
  
  df <- (sdrn1+sdrn2)^2/(sdrn1^2/(n1-1)+sdrn2^2/(n2-1))
 
  Nratio3 <- c(Nratio3,nratio)  
  DF3 <- c(DF3,df)
  coeffmult3 <- c(coeffmult3,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

#----------------------------------------------------------------------

Nratio4 <- NULL
DF4 <- NULL
coeffmult4 <- NULL

for (i in 6:100){

  sdrn1 <- 10
  sdrn2 <- 1
  
  N = 106
  n1 <- i
  n2 <- N-i
  nratio <- n1/n2
  
  df <- (sdrn1+sdrn2)^2/(sdrn1^2/(n1-1)+sdrn2^2/(n2-1))
 
  Nratio4 <- c(Nratio4,nratio)  
  DF4 <- c(DF4,df)
  coeffmult4 <- c(coeffmult4,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```


```{r biasshiehhetunbalSDRNandnpairing2case2,fig.cap="...",echo=FALSE}
par(mfrow=c(2,2))
plot(log(Nratio3),coeffmult3,main="when SDNratio1=2 and SDNratio1=1")
abline(v=log(Nratio3)[coeffmult3==min(coeffmult3)])
plot(log(Nratio4),coeffmult4,main="when SDNratio1=10 and SDNratio1=1")
abline(v=log(Nratio4)[coeffmult4==min(coeffmult4)])
plot(log(Nratio1),coeffmult1,main="when SDNratio1=1 and SDNratio1=2")
abline(v=log(Nratio1)[coeffmult1==min(coeffmult1)])
plot(log(Nratio2),coeffmult2,main="when SDNratio1=1 and SDNratio1=10")
abline(v=log(Nratio2)[coeffmult2==min(coeffmult2)])
```

  + The variances and sample sizes ratios don't matter per se (see Figure \ref{fig:biasshiehhetunbalSDRN2}). However, the pairing between these ratios and sample sizes has an effect on the bias:
    - When $\frac{\sigma^2_1}{n_1}=\frac{\sigma^2_2}{n_2}$, the smallest bias occurs when sample sizes are equal across groups. The further the sample sizes ratio is from 1, the larger the bias (see Figure \ref{fig:biasshiehhetunbalSDRNandnpairing2case1}).
    - When $\frac{\sigma^2_1}{n_1} \neq \frac{\sigma^2_2}{n_2}$, the minimum bias will always occure when $min(\frac{\sigma^2_j}{n_j})$ will be associated with $min(n_j)$. In other word, when $\frac{\sigma^2_1}{n_1}>\frac{\sigma^2_2}{n_2}$, the sample sizes ratio associated with the minimum bias will be positive, meaning that $n_1>n_2$ (and the larger the difference between $\frac{\sigma^2_1}{n_1}$ and $\frac{\sigma^2_2}{n_2}$, the further from 1 will be this sample sizes ratio; see the two top plots in Figure \ref{fig:biasshiehhetunbalSDRNandnpairing2case2}). On the other side, when $\frac{\sigma^2_1}{n_1}<\frac{\sigma^2_2}{n_2}$, the sample sizes ratio associated with the minimum bias will be negative, meaning that $n_1<n_2$ (and the larger the difference between $\frac{\sigma^2_1}{n_1}$ and $\frac{\sigma^2_2}{n_2}$, the further from 1 will be this sample sizes ratio; see the two bottom plots in Figure \ref{fig:biasshiehhetunbalSDRNandnpairing2case2}). 

```{r biasshiehhetunbalvariance,include=FALSE}
coeffmult <- NULL
SD <- NULL
DF <- NULL

for (i in 2:200){
  
  n1 <- 60
  n2 <- 12
  N <- n1+n2
  sd1 <- i
  sd2 <- 8*i
  
  df <- (sd1^2/n1+sd2^2/n2)^2/((sd1^2/n1)^2/(n1-1)+(sd2^2/n2)^2/(n2-1))
  DF <- c(DF,df)
  SD <- c(SD,sqrt((sd1^2+sd2^2)/2))
  coeffmult <- c(coeffmult,sqrt(df/2)*gamma((df-1)/2)/gamma(df/2))   
}

```

```{r biasshiehhetunbalvariance2,fig.cap="...",echo=FALSE}
par(mfrow=c(2,2))
plot(SD,DF)
abline(v=0)
plot(SD,coeffmult)
abline(v=0)
```
  
Moreover, for a constant SD-ratio, the variances don't matter either. (See Figure \ref{fig:biasshiehhetunbalvariance2})